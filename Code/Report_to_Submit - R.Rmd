---
title: "Report_to_submit_R"
author: "Ngoc Uyen PHUNG"
date: "2023-11-27"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading packages

```{r, warning=FALSE}
# Load the package
library(tidyverse)

library(readxl)
library(countrycode)
library(magrittr) # to use the pipe

# Visualization
library(hrbrthemes) # different themes for ggplot2 
library(paletteer)
library(plotly) # to have dynamic plot
```

## Custom made functions

```{r}
names_sort_count = function(data, decreasing=TRUE){
  return(
  data %>% 
    table() %>% 
    sort(decreasing = decreasing) %>% 
    names()
  )
}

cors <- function(df, type="pearson") { 
  # turn all three matrices (r, n, and P into a data frame)
  M <- Hmisc::rcorr(as.matrix(df), type = type)
  # return the three data frames in a list return(Mdf)
  Mdf <- map(M, ~data.frame(.x))
  return(Mdf)
}

formatted_cors <- function(df, type="pearson"){
  cors(df, type) %>%
    map(~rownames_to_column(.x, var="measure1")) %>%
    # format each data set (r,P,n) long
    map(~pivot_longer(.x, cols = -measure1, names_to = "measure2")) %>%
    # merge our three list elements by binding the rows
    bind_rows(.id = "id") %>%
    pivot_wider(names_from = id, values_from = value) %>%
    mutate(sig_p = ifelse(P < .05, T, F), p_if_sig = ifelse(P <.05, P, NA), r_if_sig = ifelse(P <.05, r, NA)) 
}

chisq_test_corr = function(data_frame=unicorns_corelation){
  column_names = colnames(data_frame)
  result_list <- lapply(column_names, function(i) {
    value <- chisq.test(data_frame$target_code, 
                        data_frame[[i]])$p.value
    return(data.frame(measure1 = "target_code", measure2 = i, p_value = value))
  })
  
  result_df <- do.call(rbind, result_list)
  result_df = result_df[order(result_df$p_value),]
  return (result_df)
}

fisher_test_corr = function(data_frame=unicorns_corelation){
  column_names = colnames(data_frame)
  result_list <- lapply(column_names, function(i) {
      value <- fisher.test(data_frame$target_code, 
                    data_frame[[i]], simulate.p.value = TRUE)$p.value
      return(data.frame(measure1 = "target_code", measure2 = i, p_value = value))
  })
  
  result_df <- do.call(rbind, result_list)
  result_df = result_df[order(result_df$p_value),]
  return (result_df)
}
```

# Data Processing

```{r}
# Load the data
unicorn_data <- read_excel("../DataSets/CB-Insights_Global-Unicorn-Club_2023.xlsx")
```

## Cleaning the data

```{r pressure}
# Renaming Columns
colnames(unicorn_data) <- c('company','valuation_billions','date_added','country','city','industry','select_investors')

# Removing the duplicate company 
unicorn_data = unicorn_data %>% 
  distinct( .keep_all = T)

# Removing useless columns
unicorn_data = drop_na(unicorn_data, valuation_billions)


#Sequoia Capital firm name to avoid error when creating new df "unicorn_investors"
unicorn_data$select_investors <- gsub("and Sequoia Capital China", "Sequoia Capital China", unicorn_data$select_investors)


# Dealing with missing value in "country"
unicorn_data[538, "country"] <- "Singapore"

# Remove "City" column
unicorn_data <- subset(unicorn_data, select = -city)

# Removing ",," in "Select investors" correctly count  number of investors
unicorn_data$select_investors <- gsub(",,", ",", unicorn_data$select_investors)

# Counting the number of Investors
unicorn_data$Number_of_Investors <- sapply(strsplit(as.character(unicorn_data$select_investors), ","), length)

# Replacing City names in the country variable
unicorn_data$country <- gsub("London", "United Kingdom", unicorn_data$country)
unicorn_data$country <- gsub("Munchen", "Germany", unicorn_data$country)

# continent Values
unicorn_data$continent = countrycode(sourcevar = unicorn_data$country,
                            origin = "country.name",
                            destination = "continent")

# Year Conversion 
unicorn_data$date_added = ymd(unicorn_data$date_added)

# Years since Joined
unicorn_data$age = interval(unicorn_data$date_added, now()) %/% years(1)

# Add column year
unicorn_data$year_added <- year(unicorn_data$date_added)

unicorn_data <- unicorn_data %>%
  mutate(target = 
           ifelse(valuation_billions >= 5, "Over 5 $B",  "Under 5 $B") %>% as.factor()) %>% 
  mutate(target_code = as.numeric(target) ) %>% 
  # Making Sure each company name is well differentiated from one another
  mutate(company = paste(row.names(unicorn_data), unicorn_data$company))
  
unicorn_data$industry = factor(unicorn_data$industry)
unicorn_data$continent = factor(unicorn_data$continent)
unicorn_data$country = factor(unicorn_data$country)
```

## Enriching the Data

```{r}
# Creating an intermediary dataframe for later computations
unicorn_transition <- unicorn_data %>%
  mutate(select_investors = strsplit(select_investors, ",")) %>% 
  unnest(select_investors) %>% 
  mutate(select_investors = str_trim(select_investors)) 

# Creating the investors oriented dataframe for further analysis
unicorn_investors = unicorn_transition %>% 
  summarise(.by = select_investors,
            investements_count=n(),
            investements=list(company), 
            investements_sum_valuation=sum(valuation_billions),
            investements_mean_valuation=mean(valuation_billions), 
            investements_over5B_count=sum(target_code), 
            investements_over5B_pct=investements_over5B_count/investements_count
            )

# Investor average percentage over 5B
associate_investor = unicorn_investors %>% 
  unnest(investements) %>% 
  summarise(.by = investements, 
            investements_avg_pct_over5B = mean(investements_over5B_pct)
            )


# Creating the associate companies trasition dataframe for later compuations 
associate_transition = unicorn_transition %>% 
  # Having two columns containing all the companies per Investor in a list
    summarise(.by = select_investors,
            associated_companies=list(company), 
            company=list(company)
            ) %>%
  # For each company we have their investors and a list of the companies 
  # the investors invested in. 
  unnest(company) %>% 
  # Unnesting the second column containg all the companies resulting in the 
  #duplication of all the other columns
  unnest(associated_companies) %>% 
  # Deleting the company name from the associated_company list
  # For each company, we will delete all the duplicates in the association company
  summarise(.by=company,
            associated_companies = unique(associated_companies)
            )

# Creating associate companies data frame with info regarding the associated companies

associate_companies = associate_transition %>% 
  # Deleting the company name from the associated_company list
  subset(company!=associated_companies) %>% 
  left_join(unicorn_data, by=join_by(associated_companies == company)) %>% 
  summarise(.by=company,
            associated_companies = list(unique(associated_companies)), 
            associated_count= n(),
            associated_count_over5Bill=sum(target_code), 
            associated_pct_over5Bill=associated_count_over5Bill/associated_count
            )

# Creating the associate valuation data frame with info regarding associate company valuation 
associate_valuation = associate_transition %>% 
  left_join(unicorn_data, by=join_by(associated_companies == company)) %>% 
  summarise(.by = company,
            association_total_value = sum(valuation_billions), 
            association_mean_value = mean(valuation_billions)
            )

unicorn_data_complete = unicorn_data %>% 
  left_join(associate_companies, by="company") %>% 
  left_join(associate_valuation, by="company") %>% 
  left_join(associate_investor, by=join_by(company == investements))

unicorn_data_complete = unicorn_data_complete %>% 
  mutate(associated_count = ifelse(
    is.na(associated_count), 
    0, 
    associated_count
    )
  ) %>% 
  mutate(associated_count_over5Bill = ifelse(
    is.na(associated_count_over5Bill), 
    0, 
    associated_count_over5Bill
    )
  ) %>% 
    mutate(associated_pct_over5Bill = ifelse(
    is.na(associated_pct_over5Bill), 
    0, 
    associated_pct_over5Bill
    )
  )
```

# Plots to explore the Data

```{r}

ggplot(unicorn_data, aes(x = industry)) +
  geom_bar(stat = "count", fill = "steelblue") +
  labs(title = "Distribution of the number of companies per industry") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  xlim(names_sort_count(unicorn_data$industry))

```

```{r}
ggplot(unicorn_data, aes(x = country)) +
  geom_bar(stat = "count", fill = "steelblue") +
  xlim(names_sort_count(unicorn_data$country))+
  labs(title = "Distribution of the number of companies per country") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
ggplot(unicorn_data, aes(x = continent)) +
  geom_bar(stat = "count", fill = "steelblue") +
  xlim(names_sort_count(unicorn_data$continent))+
  labs(title = "Distribution of the number of companies per country") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
ggplot(unicorn_data, aes(x = Number_of_Investors, fill = industry)) +
  geom_bar(stat = "count", position = "dodge") +
  labs(title = "Distribution of the number of investors")+
  scale_fill_paletteer_d("awtools::a_palette")
```

# Corelation : Pearson and Spearman

```{r}
unicorns_corelation = unicorn_data_complete %>% 
  select(-c(date_added, select_investors, associated_companies, valuation_billions)) %>% 
  mutate(country_code = as.numeric(country)) %>% 
  mutate(industry_code = as.numeric(industry)) %>%
  mutate(continent_code = as.numeric(continent))

unicorns_corelation %>% 
  summary()
  
unicorns_corelation = unicorns_corelation %>% 
  select(-c(company, country, industry, target, continent, year_added))
```

## Correlation Matrix

```{r, fig.height=6.4, fig.width=8}
formatted_cors(unicorns_corelation) %>% 
  ggplot(aes(measure1, measure2, fill=r, label=round(r_if_sig,2))) +
  geom_tile() +
  labs(x = NULL, y = NULL, fill = "Pearson's\nCorrelation", title="Correlations in Unicorn_Corelation", subtitle="Only significant Pearson's correlation coefficients shown") +
  scale_fill_gradient2(mid="#FBFEF9",low="#0C6291",high="#A63446", limits=c(-1,1)) +
  geom_text() +
  theme_classic() +
  scale_x_discrete(expand=c(0,0)) +
  scale_y_discrete(expand=c(0,0)) +
  theme(axis.text.x = element_text(angle = 45, hjust=1))
```

```{r, fig.height=6.4, fig.width=8}
formatted_cors(unicorns_corelation, "spearman") %>% 
  ggplot(aes(measure1, measure2, fill=r, label=round(r_if_sig,2))) +
  geom_tile() +
  labs(x = NULL, y = NULL, fill = "Spearman's\nCorrelation", title="Correlations in Unicorn_Corelation", subtitle="Only significant Pearson's correlation coefficients shown") +
  scale_fill_gradient2(mid="#FBFEF9",low="#0C6291",high="#A63446", limits=c(-1,1)) +
  geom_text() +
  theme_classic() +
  scale_x_discrete(expand=c(0,0)) +
  scale_y_discrete(expand=c(0,0)) +
  theme(axis.text.x = element_text(angle = 45, hjust=1))
```

# Corelation : Khi2 and Fisher
```{r}
chisq_test_data = chisq_test_corr() 

chisq_test_data %>% 
  ggplot(aes(x=measure2, y=p_value)) +
  geom_segment( aes(x=measure2, xend=measure2, y=0, yend=p_value), color="skyblue") +
  geom_point( color="blue", size=4, alpha=0.6) +
  theme_light() +
  coord_flip() +
  theme(
    panel.grid.major.y = element_blank(),
    panel.border = element_blank(),
    axis.ticks.y = element_blank()
  ) +
  scale_y_continuous(breaks = seq(0, 1, 0.1), labels = scales::percent_format(scale = 1)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "red")+
  xlim(chisq_test_data$measure2)+
  labs(x = NULL, title="Khi2 correlations between all varaibles and Target")

```

```{r}
fisher_test_data = fisher_test_corr() 

fisher_test_data %>% 
  ggplot(aes(x=measure2, y=p_value)) +
  geom_segment( aes(x=measure2, xend=measure2, y=0, yend=p_value), color="skyblue") +
  geom_point( color="blue", size=4, alpha=0.6) +
  theme_light() +
  coord_flip() +
  theme(
    panel.grid.major.y = element_blank(),
    panel.border = element_blank(),
    axis.ticks.y = element_blank()
  ) +
  scale_y_continuous(breaks = seq(0, 1, 0.1), labels = scales::percent_format(scale = 1)) +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "red")+
  xlim(fisher_test_data$measure2)+
  labs(x = NULL, title="Fisher correlations between all varaibles and Target")
```


# Model Building

## Dataset splitting

```{r}
# Training set and test set
set.seed(100)
row.number <- sample(1:nrow(unicorn_data_complete), 0.8*nrow(unicorn_data_complete))
train=unicorn_data_complete[row.number,]
test=unicorn_data_complete[-row.number,]

# Splitting efficiency check 

prop.table(table(unicorn_data_complete$target))
prop.table(table(train$target))
prop.table(table(test$target))

```

Overall we have a higher proportion of Under 5 \$B, that evenly distributed in each sets.

# Logistic Regression

## Train

```{r}
logit_model <- glm (target ~year_added + age + Number_of_Investors + 
    associated_count + associated_count_over5Bill + associated_pct_over5Bill + 
    association_total_value + association_mean_value + investements_avg_pct_over5B, 
                      data=train,binomial(link="logit"))
summary(logit_model)
```

## Performance evaluation

```{r}
library(gmodels) 
logit_prediction_test <- predict(logit_model, newdata = test, type = "response")

prop.table(table(logit_prediction_test >0.5,test$target))

CrossTable(logit_prediction_test>0.5,test$target, prop.chisq=FALSE,
chisq=FALSE,prop.t=FALSE,dnn = c("Predicted","Actual"))
```

# Decision Tree

```{r Library}
library(rpart)
library(rpart.plot)
```

##Train Decision Tree model

```{r}
decision_tree <- rpart(target~year_added + age + Number_of_Investors + associated_count + associated_count_over5Bill + associated_pct_over5Bill + association_total_value + association_mean_value + investements_avg_pct_over5B,
method="class", data=train,
control=rpart.control(minsplit=1),
parms=list(split="information"))
```

## Plot the decision tree

```{r}
rpart.plot(decision_tree, type=2, extra=1)
```

```{r}
tree_prediction_test <- predict(decision_tree,newdata=test,type="class")
```

```{r}
# Confusion matrix for decision tree
confusion_tree <- table(tree_prediction_test, test$target)

# Display confusion matrix
print(confusion_tree)

# Calculate accuracy for decision tree
accuracy_tree <- sum(diag(confusion_tree))/sum(confusion_tree)
print(paste("Accuracy for Decision Tree:", accuracy_tree))

# CrossTable function for a more detailed analysis
CrossTable(tree_prediction_test, test$target, prop.chisq=FALSE,
           chisq=FALSE, prop.t=FALSE, dnn = c("Predicted", "Actual"))
```

# NaÃ¯ve Bayes

```{r}
# Load necessary libraries
library(e1071)  # For Naive Bayes
```

## Train the Naive Bayes model
```{r}
unicorn_data_complete$country<-factor(unicorn_data_complete$country)
unicorn_data_complete$industry<-factor(unicorn_data_complete$industry)
unicorn_data_complete$continent<-factor(unicorn_data_complete$continent)
unicorn_data_complete$Number_of_Investors<-factor(unicorn_data_complete$Number_of_Investors)
unicorn_data_complete$year_added<-factor(unicorn_data_complete$year_added)
unicorn_data_complete$age<-factor(unicorn_data_complete$age)
unicorn_data_complete$associated_count<-factor(unicorn_data_complete$associated_count)
unicorn_data_complete$associated_count_over5Bill<-factor(unicorn_data_complete$associated_count_over5Bill)
unicorn_data_complete$associated_pct_over5Bill<-factor(unicorn_data_complete$associated_pct_over5Bill)
unicorn_data_complete$association_total_value<-factor(unicorn_data_complete$association_total_value)
unicorn_data_complete$association_mean_value<-factor(unicorn_data_complete$association_mean_value)
unicorn_data_complete$investements_avg_pct_over5B<-factor(unicorn_data_complete$investements_avg_pct_over5B)
```

```{r}
naive_bayes_model <- naiveBayes(target ~ year_added + age + Number_of_Investors + 
                                  associated_count + associated_count_over5Bill + 
                                  associated_pct_over5Bill + association_total_value + 
                                  association_mean_value + investements_avg_pct_over5B, 
                                data = train)


```
